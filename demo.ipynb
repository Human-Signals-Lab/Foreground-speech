{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score, classification_report, mutual_info_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_features(feat_path, feat_type):\n",
    "    \"\"\"\n",
    "    Func to load the features and labels\n",
    "    Args:\n",
    "        feat_path\n",
    "        feat_type: 'emb1' or 'emb2'\n",
    "    return:\n",
    "        features: [# samples, feat dimension]\n",
    "        labels: [# samples]\n",
    "    \"\"\"\n",
    "    if feat_type == 'emb1':\n",
    "        feat_size = 512 \n",
    "    elif feat_type == 'emb2':\n",
    "        feat_size = 1000\n",
    "    else:\n",
    "        print('feat_type not supported!')\n",
    "    f = []\n",
    "    for fp in feat_path:\n",
    "        a = pd.read_csv(fp, delimiter=',', header=None, dtype=str).values\n",
    "        f.append(a)\n",
    "    f = np.concatenate(f, axis = 0)\n",
    "\n",
    "    return f[:, :feat_size].astype(float), f[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(test_embedding, test_labels):\n",
    "    \"\"\"\n",
    "    Func to filter invalid instances and unify the labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # obtain valid test sounds\n",
    "    idx_valid_voice = np.where(test_labels != 'x')            \n",
    "    test_labels_filtered = np.copy(test_labels[idx_valid_voice])\n",
    "\n",
    "    test_embedding_filtered = np.copy(test_embedding[idx_valid_voice])\n",
    "    # shuffle the embeddings\n",
    "    test_embedding_filtered, test_labels_filtered = shuffle(test_embedding_filtered, test_labels_filtered, random_state=0)\n",
    "    \n",
    "    print('valid test data size:', sub, len(test_labels_filtered), \n",
    "          'ambiguous (x) size:', len(test_labels) - len(test_labels_filtered))\n",
    "    \n",
    "\n",
    "    # Change test sound labels to a consistent format, '1' for wearer, '2' for non-wearer.\n",
    "    idx_wearer_voice = np.where(test_labels_filtered == '1')   # wearer\n",
    "    test_labels_filtered[idx_wearer_voice] = 1\n",
    "    idx_other_voice = np.where(test_labels_filtered == 'm')   # mixed counted as wearer\n",
    "    test_labels_filtered[idx_other_voice] = 1\n",
    "    idx_other_voice = np.where(test_labels_filtered == '2')   # non-wearer speech\n",
    "    test_labels_filtered[idx_other_voice] = 2\n",
    "    idx_other_voice = np.where(test_labels_filtered == 'c')   # baby crying\n",
    "    test_labels_filtered[idx_other_voice] = 2\n",
    "    idx_other_voice = np.where(test_labels_filtered == 'p')   # phone call\n",
    "    test_labels_filtered[idx_other_voice] = 2   \n",
    "    idx_other_voice = np.where(test_labels_filtered == 't')   # TV\n",
    "    test_labels_filtered[idx_other_voice] = 2 \n",
    "    idx_noise = np.where(test_labels_filtered == 'b')   # non-vocal background\n",
    "    test_labels_filtered[idx_noise] = 2\n",
    "    \n",
    "    test_labels_filtered = test_labels_filtered.astype(int)  \n",
    "    \n",
    "    return test_embedding_filtered, test_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded test data size: P1 6862\n",
      "valid test data size: P1 6740 ambiguous (x) size: 122\n",
      "cluster0 (smaller sim from centroid) is the foreground\n",
      "sub P1 balanced accuracy 0.820521 macro f1 0.804265\n",
      "loaded test data size: P2 4627\n",
      "valid test data size: P2 4465 ambiguous (x) size: 162\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P2 balanced accuracy 0.839438 macro f1 0.848876\n",
      "loaded test data size: P3 4927\n",
      "valid test data size: P3 4847 ambiguous (x) size: 80\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P3 balanced accuracy 0.774472 macro f1 0.775020\n",
      "loaded test data size: P4 6652\n",
      "valid test data size: P4 6639 ambiguous (x) size: 13\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P4 balanced accuracy 0.775307 macro f1 0.813661\n",
      "loaded test data size: P5 4568\n",
      "valid test data size: P5 4451 ambiguous (x) size: 117\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P5 balanced accuracy 0.854646 macro f1 0.839060\n",
      "loaded test data size: P6 6424\n",
      "valid test data size: P6 6406 ambiguous (x) size: 18\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P6 balanced accuracy 0.858101 macro f1 0.882150\n",
      "loaded test data size: P7 6446\n",
      "valid test data size: P7 6427 ambiguous (x) size: 19\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P7 balanced accuracy 0.789959 macro f1 0.831926\n",
      "loaded test data size: P8 8307\n",
      "valid test data size: P8 8287 ambiguous (x) size: 20\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P8 balanced accuracy 0.724030 macro f1 0.651888\n",
      "loaded test data size: P9 6821\n",
      "valid test data size: P9 6777 ambiguous (x) size: 44\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P9 balanced accuracy 0.762095 macro f1 0.757097\n",
      "loaded test data size: P10 6380\n",
      "valid test data size: P10 6317 ambiguous (x) size: 63\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P10 balanced accuracy 0.775059 macro f1 0.788480\n",
      "loaded test data size: P11 6720\n",
      "valid test data size: P11 6701 ambiguous (x) size: 19\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P11 balanced accuracy 0.791406 macro f1 0.793012\n",
      "loaded test data size: P12 6858\n",
      "valid test data size: P12 6414 ambiguous (x) size: 444\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P12 balanced accuracy 0.753666 macro f1 0.746943\n",
      "loaded test data size: P13 7398\n",
      "valid test data size: P13 7391 ambiguous (x) size: 7\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P13 balanced accuracy 0.776528 macro f1 0.782477\n",
      "loaded test data size: P14 6220\n",
      "valid test data size: P14 6220 ambiguous (x) size: 0\n",
      "cluster0 (smaller sim from centroid) is the foreground\n",
      "sub P14 balanced accuracy 0.839490 macro f1 0.799533\n",
      "loaded test data size: P15 4677\n",
      "valid test data size: P15 4664 ambiguous (x) size: 13\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P15 balanced accuracy 0.710602 macro f1 0.747762\n",
      "loaded test data size: P16 9541\n",
      "valid test data size: P16 9525 ambiguous (x) size: 16\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P16 balanced accuracy 0.835431 macro f1 0.832306\n",
      "loaded test data size: P17 3323\n",
      "valid test data size: P17 3273 ambiguous (x) size: 50\n",
      "cluster1 (smaller sim from centroid) is the foreground\n",
      "sub P17 balanced accuracy 0.784823 macro f1 0.800423\n",
      "loaded test data size: P18 4672\n",
      "valid test data size: P18 4672 ambiguous (x) size: 0\n",
      "cluster0 (smaller sim from centroid) is the foreground\n",
      "sub P18 balanced accuracy 0.739864 macro f1 0.721530\n",
      "mean balanced acc all groups: 0.789190957091805\n",
      "mean macro f1 all groups: 0.7898004899396761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "feat_type = 'emb2'   # use emb1 or emb2\n",
    "sub_list = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15',\n",
    "            'P16', 'P17', 'P18']   # study group to test\n",
    "\n",
    "acc_container = []   # used for len(sub) > 1\n",
    "f1_container = []   # used for len(sub) > 1\n",
    "   \n",
    "for sub in sub_list:\n",
    "    # Load data \n",
    "    test_feat_path = ['./embeddings/%s/%s/call.csv' %(sub, feat_type),\n",
    "                     './embeddings/%s/%s/dinner.csv' %(sub, feat_type),\n",
    "                     './embeddings/%s/%s/game.csv' %(sub, feat_type),\n",
    "                     './embeddings/%s/%s/outdoor.csv' %(sub, feat_type),\n",
    "                     './embeddings/%s/%s/TV.csv' %(sub, feat_type)]    \n",
    "\n",
    "    test_embedding, test_labels = load_multiple_features(test_feat_path, feat_type = feat_type)    \n",
    "    print('loaded test data size:', sub, len(test_labels))\n",
    "\n",
    "    # group 16-18 is labeled by int [0, 1] only, so we need to cast something like '1.0' to '1' in labels\n",
    "    for i in range(len(test_labels)):\n",
    "        try:\n",
    "            test_labels[i] = str(int(float(test_labels[i])))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    test_embedding_filtered, test_labels_filtered = pre_processing(test_embedding, test_labels)\n",
    "    \n",
    "    \n",
    "        \n",
    "    D = pairwise_distances(test_embedding_filtered, metric='cosine')\n",
    "            \n",
    "    # The clustering methods to use\n",
    "    #clf = KMedoids(n_clusters=2, metric='cosine', max_iter=1000, method='pam', random_state=0)\n",
    "    clf = SpectralClustering(n_clusters=2, affinity='cosine', eigen_solver='arpack', random_state=0, n_jobs=-1)\n",
    "\n",
    "    # prediction\n",
    "    clustered_labels = clf.fit_predict(test_embedding_filtered) \n",
    "    idx_cluster_0 = np.where(clustered_labels == 0)\n",
    "    idx_cluster_1 = np.where(clustered_labels == 1)\n",
    "\n",
    "    # calculate the center for each cluster\n",
    "    mean_embedding_cluster_0 = np.mean(test_embedding_filtered[idx_cluster_0], axis=0)\n",
    "    mean_embedding_cluster_1 = np.mean(test_embedding_filtered[idx_cluster_1], axis=0)\n",
    "\n",
    "    # compare similarity from center for each cluster    \n",
    "    sim0, sim1 = [], []\n",
    "    for i in range(len(test_embedding_filtered[idx_cluster_0])):\n",
    "        sim0.append(cosine_similarity(mean_embedding_cluster_0.reshape(1, -1), \n",
    "                                      test_embedding_filtered[idx_cluster_0][i].reshape(1, -1))[0][0])\n",
    "    for i in range(len(test_embedding_filtered[idx_cluster_1])):\n",
    "        sim1.append(cosine_similarity(mean_embedding_cluster_1.reshape(1, -1), \n",
    "                                      test_embedding_filtered[idx_cluster_1][i].reshape(1, -1))[0][0])\n",
    "    # bigger s indicates the background cluster\n",
    "    if np.mean(sim0) > np.mean(sim1):\n",
    "        print('cluster1 (smaller sim from centroid) is the foreground')\n",
    "        clustered_labels[idx_cluster_0] = 2\n",
    "        clustered_labels[idx_cluster_1] = 1\n",
    "    else:\n",
    "        print('cluster0 (smaller sim from centroid) is the foreground')\n",
    "        clustered_labels[idx_cluster_1] = 2\n",
    "        clustered_labels[idx_cluster_0] = 1\n",
    "            \n",
    "    acc = balanced_accuracy_score(test_labels_filtered, clustered_labels)               \n",
    "    f1 = f1_score(test_labels_filtered, clustered_labels, average = 'macro')\n",
    "        \n",
    "    # print classification result\n",
    "    print('sub %s balanced accuracy %f macro f1 %f' %(sub, acc, f1))                                                                                 \n",
    "    acc_container.append(acc)\n",
    "    f1_container.append(f1)\n",
    "    \n",
    "print('mean balanced acc all groups:', np.mean(acc_container))\n",
    "print('mean macro f1 all groups:', np.mean(f1_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
